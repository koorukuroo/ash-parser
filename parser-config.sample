decaySteps = 4400
averagingDecay = 0.9999
learningRate = 0.08
momentum = 0.85

# For sample training set
# 931 feature bags at batch size 512
# 6501 feature bags at batch size 64 (performs better)
batchSize = 64

# How many predictions to consider
topK = 10

projectivizeTrainingSet = True

hiddenLayerSizes = [256, 256]

embeddingSizes = {'tag': 32, 'label': 32, 'word': 64}

# same as Parsey McParseface
# https://github.com/tensorflow/models/blob/master/syntaxnet/syntaxnet/models/parsey_mcparseface/context.pbtxt
featureStrings = [
    'stack.child(1).label',
    'stack.child(1).sibling(-1).label',
    'stack.child(-1).label',
    'stack.child(-1).sibling(1).label',
    'stack.child(2).label',
    'stack.child(-2).label',
    'stack(1).child(1).label',
    'stack(1).child(1).sibling(-1).label',
    'stack(1).child(-1).label',
    'stack(1).child(-1).sibling(1).label',
    'stack(1).child(2).label',
    'stack(1).child(-2).label',
    'input.tag',
    'input(1).tag',
    'input(2).tag',
    'input(3).tag',
    'stack.tag',
    'stack.child(1).tag',
    'stack.child(1).sibling(-1).tag',
    'stack.child(-1).tag',
    'stack.child(-1).sibling(1).tag',
    'stack.child(2).tag',
    'stack.child(-2).tag',
    'stack(1).tag',
    'stack(1).child(1).tag',
    'stack(1).child(1).sibling(-1).tag',
    'stack(1).child(-1).tag',
    'stack(1).child(-1).sibling(1).tag',
    'stack(1).child(2).tag',
    'stack(1).child(-2).tag',
    'stack(2).tag',
    'stack(3).tag',
    'input.word',
    'input(1).word',
    'input(2).word',
    'input(3).word',
    'stack.word',
    'stack.child(1).word',
    'stack.child(1).sibling(-1).word',
    'stack.child(-1).word',
    'stack.child(-1).sibling(1).word',
    'stack.child(2).word',
    'stack.child(-2).word',
    'stack(1).word',
    'stack(1).child(1).word',
    'stack(1).child(1).sibling(-1).word',
    'stack(1).child(-1).word',
    'stack(1).child(-1).sibling(1).word',
    'stack(1).child(2).word',
    'stack(1).child(-2).word',
    'stack(2).word',
    'stack(3).word'
]
